# Module for interpreting signals from different channels 

import logging
import re

logger = logging.getLogger(__name__)

# # –°–ª–æ–≤–Ω–∏–∫ –∑ –Ω–∞–∑–≤–∞–º–∏ –∫–∞–Ω–∞–ª—ñ–≤ –±—ñ–ª—å—à–µ –Ω–µ –ø–æ—Ç—Ä—ñ–±–µ–Ω —Ç—É—Ç, –±–µ—Ä–µ–º–æ –∑ –∫–æ–Ω—Ñ—ñ–≥—É
# CHANNEL_NAME_MAP = {
#     "VIP –º–∞—Ä–∞—Ñ–æ–Ω | –î–∞–Ω–∏—ç–ª—å": "channel_1",
#     "Crypto Alliance | –ú–∞—Ä—Ç–∏–Ω": "channel_2",
#     "–í–Ω—É—Ç—Ä–∏ –≥—Ä–∞—Ñ–∏–∫–∞ —Å –î–∂–∏–º–º–∏": "channel_3",
#     "KostyaKogan": "channel_4",
# }

# --- Helper function to safely convert string to float ---
def safe_float(value_str):
    if value_str is None:
        return None
    try:
        # Replace comma with dot if needed, remove spaces
        return float(value_str.replace(",", ".").strip())
    except (ValueError, TypeError):
        return None

# --- Helper function to normalize trading pair ---
def normalize_pair(pair_str):
    if pair_str is None:
        return None
    pair = pair_str.upper().replace("/", "").strip()
    # Assume USDT if only base currency is provided
    if not any(quote in pair for quote in ["USDT", "BTC", "ETH"]): # Add other potential quote currencies if needed
        pair += "USDT"
    return pair

# --- Function to identify the channel ---
def identify_signal_source(forwarded_channel_title: str, config: dict):
    """–í–∏–∑–Ω–∞—á–∞—î –∫–ª—é—á –∫–∞–Ω–∞–ª—É –∑–∞ –π–æ–≥–æ –Ω–∞–∑–≤–æ—é –∑ Telegram API."""
    logger.debug(f"–í–∏–∑–Ω–∞—á–∞—é –¥–∂–µ—Ä–µ–ª–æ –∑–∞ –Ω–∞–∑–≤–æ—é: '{forwarded_channel_title}'")
    for key, channel_data in config.get('channels', {}).items():
        name_from_config = channel_data.get('name')
        if name_from_config and forwarded_channel_title == name_from_config:
            logger.debug(f"–î–∂–µ—Ä–µ–ª–æ –≤–∏–∑–Ω–∞—á–µ–Ω–æ: key={key}, name={name_from_config}")
            return key, name_from_config # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –∫–ª—é—á —ñ –Ω–∞–∑–≤—É
    logger.info(f"–ù–∞–∑–≤–∞ –∫–∞–Ω–∞–ª—É '{forwarded_channel_title}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞ –≤ config.json.")
    return None, None # –Ø–∫—â–æ –∫–∞–Ω–∞–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ

# --- Channel-specific parsers --- 

def parse_channel_1_entry(text: str):
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –ü–ï–†–®–û–ì–û –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–∞–Ω–∞–ª—É 1 ('–ó–∞–ø–æ–ª–Ω—è—é...')."""
    logger.debug("  [C1 Entry] –°–ø—Ä–æ–±–∞ –ø–∞—Ä—Å–∏–Ω–≥—É —è–∫ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è '–ó–∞–ø–æ–ª–Ω—è—é...'")
    # –ü–∞—Ç–µ—Ä–Ω: "–ó–∞–ø–æ–ª–Ω—è—é" + –ø—Ä–æ–±—ñ–ª + (–°–ª–æ–≤–æ) + –ø—Ä–æ–±—ñ–ª + (long –∞–±–æ short)
    match = re.search(r"–ó–∞–ø–æ–ª–Ω—è—é\s+(\w+)\s+(long|short)", text, re.IGNORECASE)
    if match:
        pair = normalize_pair(match.group(1))
        direction = match.group(2).upper()
        logger.info(f"  [C1 Entry] –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ –≤—Ö—ñ–¥–Ω–∏–π —Å–∏–≥–Ω–∞–ª: Pair={pair}, Direction={direction}")
        return {"type": "entry", "pair": pair, "direction": direction}
    logger.debug("  [C1 Entry] –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ç–µ—Ä–Ω '–ó–∞–ø–æ–ª–Ω—è—é...'")
    return None

def parse_channel_1_details(text: str, config: dict):
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –î–†–£–ì–û–ì–û –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–∞–Ω–∞–ª—É 1 (–∑ –¥–µ—Ç–∞–ª—è–º–∏ TP/SL)."""
    logger.debug("  [C1 Details] –°–ø—Ä–æ–±–∞ –ø–∞—Ä—Å–∏–Ω–≥—É —è–∫ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑ –¥–µ—Ç–∞–ª—è–º–∏ (–ú–æ–Ω–µ—Ç–∞:...)")
    signal_data = {
        "type": "details", # –î–æ–¥–∞—î–º–æ —Ç–∏–ø –¥–ª—è —Ä–æ–∑—Ä—ñ–∑–Ω–µ–Ω–Ω—è
        "source": "channel_1",
        "source_name": config['channels']['channel_1']['name'],
        "pair": None,
        "direction": None, # –ù–∞–ø—Ä—è–º–æ–∫ —Ç–µ–∂ —î –≤ —Ü—å–æ–º—É –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—ñ
        "entry_price": None,
        "take_profits": [],
        "stop_loss": None,
        "raw_text": text,
    }

    try:
        # 1. –ü–∞—Ä–∞ —Ç–∞ –Ω–∞–ø—Ä—è–º–æ–∫ (–∑ —Ä—è–¥–∫–∞ "–ú–æ–Ω–µ—Ç–∞: ...")
        pair_match = re.search(r"–ú–æ–Ω–µ—Ç–∞:\s+(\w+)\s+(LONG|SHORT)", text, re.IGNORECASE)
        if pair_match:
            signal_data["pair"] = normalize_pair(pair_match.group(1))
            signal_data["direction"] = pair_match.group(2).upper()
            logger.debug(f"  [C1 Details] –ó–Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä—É: {signal_data['pair']}, –Ω–∞–ø—Ä—è–º–æ–∫: {signal_data['direction']}")
        else:
            logger.warning("  [C1 Details] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –ø–∞—Ä—É —Ç–∞ –Ω–∞–ø—Ä—è–º–æ–∫ ('–ú–æ–Ω–µ—Ç–∞:...').")
            return None # –í–≤–∞–∂–∞—î–º–æ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–º –¥–ª—è —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—ó

        # 2. –¶—ñ–Ω–∞ –≤—Ö–æ–¥—É
        entry_match = re.search(r"–¶–µ–Ω–∞ –≤—Ö–æ–¥–∞:\s*([\d.,]+)", text)
        if entry_match:
            signal_data["entry_price"] = safe_float(entry_match.group(1))
            logger.debug(f"  [C1 Details] –ó–Ω–∞–π–¥–µ–Ω–æ —Ü—ñ–Ω—É –≤—Ö–æ–¥—É: {signal_data['entry_price']}")
        # –ù–µ —Ä–æ–±–∏–º–æ return None, –º–æ–∂–ª–∏–≤–æ —Ü—ñ–Ω–∞ –≤—Ö–æ–¥—É –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–∞ –¥–ª—è –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è SL/TP?
        # –ê–ª–µ –∫—Ä–∞—â–µ –∑–∞–ª–∏—à–∏—Ç–∏ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–º –¥–ª—è –ø–æ–≤–Ω–æ—Ç–∏ –¥–∞–Ω–∏—Ö
        # else:
        #     logger.warning("  [C1 Details] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ü—ñ–Ω—É –≤—Ö–æ–¥—É.")
        #     return None 

        # 3. –¢–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏
        tp_match = re.search(r"–¢—ç–π–∫–∏:\s*([\d.,\s]+)", text)
        if tp_match:
            tp_str = tp_match.group(1).strip()
            signal_data["take_profits"] = [p for p in (safe_float(val) for val in tp_str.split()) if p is not None]
            logger.debug(f"  [C1 Details] –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏: {signal_data['take_profits']}")
        else:
            logger.warning("  [C1 Details] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ç–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏.")

        # 4. –°—Ç–æ–ø-–ª–æ—Å—Å
        sl_match = re.search(r"–°—Ç–æ–ø:\s*([\d.,]+)", text)
        if sl_match:
            signal_data["stop_loss"] = safe_float(sl_match.group(1))
            logger.debug(f"  [C1 Details] –ó–Ω–∞–π–¥–µ–Ω–æ —Å—Ç–æ–ø-–ª–æ—Å—Å: {signal_data['stop_loss']}")
        else:
            logger.warning("  [C1 Details] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Å—Ç–æ–ø-–ª–æ—Å—Å.")
            return None # –û–±–æ–≤'—è–∑–∫–æ–≤–µ –ø–æ–ª–µ –¥–ª—è –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –æ—Ä–¥–µ—Ä—ñ–≤

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏—Ö –ø–æ–ª—ñ–≤ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π
        if not all([signal_data["pair"], signal_data["direction"], signal_data["stop_loss"]]):
             logger.warning("  [C1 Details] –ù–µ –≤—Å—ñ –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ –ø–æ–ª—è (pair, direction, stop_loss) –±—É–ª–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ.")
             return None
             
        logger.info(f"  [C1 Details] –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ –¥–µ—Ç–∞–ª—ñ —Å–∏–≥–Ω–∞–ª—É: { {k: v for k, v in signal_data.items() if k != 'raw_text'} }")
        return signal_data

    except Exception as e:
        logger.error(f"  [C1 Details] –ù–µ–æ—á—ñ–∫—É–≤–∞–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–∞—Ä—Å–∏–Ω–≥—É –¥–µ—Ç–∞–ª–µ–π –∫–∞–Ω–∞–ª—É 1: {e}", exc_info=True)
        return None

# --- –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è —ñ–Ω—à–∏—Ö –∫–∞–Ω–∞–ª—ñ–≤ (–¥–æ–¥–∞—î–º–æ type) ---
def parse_channel_2(text: str, config: dict):
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∫–∞–Ω–∞–ª—É 2 (Crypto Alliance | –ú–∞—Ä—Ç–∏–Ω)."""
    logger.info(f"–í–∏–∫–ª–∏–∫–∞–Ω–æ –ø–∞—Ä—Å–µ—Ä –¥–ª—è –∫–∞–Ω–∞–ª—É 2 ({config['channels']['channel_2']['name']}).")
    signal_data = {
        "type": "full",
        "source": "channel_2",
        "source_name": config['channels']['channel_2']['name'],
        "pair": None,
        "direction": None,
        "entry_price": None,
        "take_profits": [],
        "stop_loss": None,
        "raw_text": text,
    }

    try:
        # 1. –ü–∞—Ä–∞ —Ç–∞ –Ω–∞–ø—Ä—è–º–æ–∫
        pair_match = re.search(r"–ó–∞—Ö–æ–¥–∏–º\s+([\w\/]+)\s+(long|short)", text, re.IGNORECASE)
        if pair_match:
            signal_data["pair"] = normalize_pair(pair_match.group(1))
            signal_data["direction"] = pair_match.group(2).upper()
            logger.debug(f"  [C2] –ó–Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä—É: {signal_data['pair']}, –Ω–∞–ø—Ä—è–º–æ–∫: {signal_data['direction']}")
        else:
            logger.warning("  [C2] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –ø–∞—Ä—É —Ç–∞ –Ω–∞–ø—Ä—è–º–æ–∫ ('–ó–∞—Ö–æ–¥–∏–º...').")
            return None # –û–±–æ–≤'—è–∑–∫–æ–≤—ñ

        # 2. –¶—ñ–Ω–∞ –≤—Ö–æ–¥—É (–®—É–∫–∞—î–º–æ —Ç–µ–∫—Å—Ç –ø—ñ—Å–ª—è –¥–≤–æ–∫—Ä–∞–ø–∫–∏)
        entry_match = re.search(r"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞:\s*([\d.,]+)", text, re.IGNORECASE)
        if entry_match:
            signal_data["entry_price"] = safe_float(entry_match.group(1))
            logger.debug(f"  [C2] –ó–Ω–∞–π–¥–µ–Ω–æ —Ü—ñ–Ω—É –≤—Ö–æ–¥—É: {signal_data['entry_price']}")
        else:
            logger.warning("  [C2] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ü—ñ–Ω—É –≤—Ö–æ–¥—É ('–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞:...').")
            return None # –û–±–æ–≤'—è–∑–∫–æ–≤–µ

        # 3. –¢–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏ (–®—É–∫–∞—î–º–æ —Ç–µ–∫—Å—Ç –ø—ñ—Å–ª—è –¥–≤–æ–∫—Ä–∞–ø–∫–∏, —Ä–æ–∑–¥—ñ–ª—è—î–º–æ –ø–æ " - ")
        tp_match = re.search(r"–¢–µ–π–∫–∏:\s*(.+)", text, re.IGNORECASE)
        if tp_match:
            tp_str = tp_match.group(1).strip()
            # –†–æ–∑–¥—ñ–ª—è—î–º–æ –ø–æ " - ", –æ—á–∏—â—É—î–º–æ –≤—ñ–¥ –ø—Ä–æ–±—ñ–ª—ñ–≤ –Ω–∞–≤–∫–æ–ª–æ —á–∏—Å–µ–ª
            signal_data["take_profits"] = [p for p in (safe_float(val.strip()) for val in tp_str.split(' - ')) if p is not None]
            logger.debug(f"  [C2] –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏: {signal_data['take_profits']}")
        else:
            logger.warning("  [C2] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ç–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏ ('–¢–µ–π–∫–∏:...').")
            # –¢–µ–π–∫–∏ –º–æ–∂—É—Ç—å –±—É—Ç–∏ –Ω–µ–æ–±–æ–≤'—è–∑–∫–æ–≤–∏–º–∏

        # 4. –°—Ç–æ–ø-–ª–æ—Å—Å (–®—É–∫–∞—î–º–æ —Ç–µ–∫—Å—Ç –ø—ñ—Å–ª—è –¥–≤–æ–∫—Ä–∞–ø–∫–∏)
        sl_match = re.search(r"–°—Ç–æ–ø:\s*([\d.,]+)", text, re.IGNORECASE)
        if sl_match:
            signal_data["stop_loss"] = safe_float(sl_match.group(1))
            logger.debug(f"  [C2] –ó–Ω–∞–π–¥–µ–Ω–æ —Å—Ç–æ–ø-–ª–æ—Å—Å: {signal_data['stop_loss']}")
        else:
            logger.warning("  [C2] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Å—Ç–æ–ø-–ª–æ—Å—Å ('–°—Ç–æ–ø:...'). –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ None.")
            signal_data["stop_loss"] = None # –Ø–≤–Ω–æ –≤—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ None, —è–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ
            # return None # –í–∏–¥–∞–ª—è—î–º–æ return None, —â–æ–± –∑—Ä–æ–±–∏—Ç–∏ SL –Ω–µ–æ–±–æ–≤'—è–∑–∫–æ–≤–∏–º

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏—Ö –ø–æ–ª—ñ–≤ (–≤–∏–∫–ª—é—á–∞—é—á–∏ stop_loss)
        if not all([signal_data["pair"], signal_data["direction"], signal_data["entry_price"]]):
             logger.warning("  [C2] –ù–µ –≤—Å—ñ –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ –ø–æ–ª—è (pair, direction, entry_price) –±—É–ª–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ.")
             return None

        logger.info(f"  [C2] –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ —Å–∏–≥–Ω–∞–ª: { {k: v for k, v in signal_data.items() if k != 'raw_text'} }")
        return signal_data

    except Exception as e:
        logger.error(f"  [C2] –ù–µ–æ—á—ñ–∫—É–≤–∞–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–∞—Ä—Å–∏–Ω–≥—É –∫–∞–Ω–∞–ª—É 2: {e}", exc_info=True)
        return None

def parse_channel_3(text: str, config: dict):
    logger.info(f"–í–∏–∫–ª–∏–∫–∞–Ω–æ –ø–∞—Ä—Å–µ—Ä –¥–ª—è –∫–∞–Ω–∞–ª—É 3 ({config['channels']['channel_3']['name']}).")
    # --- Log the exact text being parsed ---
    logger.debug(f"  [C3] –¢–µ–∫—Å—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É (repr): {repr(text)}")
    logger.debug(f"  [C3] –¢–µ–∫—Å—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É (raw):\n---\n{text}\n---")

    signal_data = {
        "type": "full",
        "source": "channel_3",
        "source_name": config['channels']['channel_3']['name'],
        "pair": None,
        "direction": None,
        "entry_price": "MARKET",
        "limit_order_price": None,
        "take_profits": [],
        "stop_loss": None,
        "raw_text": text,
    }

    try:
        # 1. –ù–∞–ø—Ä—è–º–æ–∫ —Ç–∞ –¥—ñ–∞–ø–∞–∑–æ–Ω —Ü—ñ–Ω (–∑ –Ω—å–æ–≥–æ –±–µ—Ä–µ–º–æ —Ü—ñ–Ω—É –¥–ª—è –ª—ñ–º—ñ—Ç–∫–∏)
        # –ó—Ä–æ–±–∏–º–æ regex –±—ñ–ª—å—à –≥–Ω—É—á–∫–∏–º –¥–æ –ø—Ä–æ–±—ñ–ª—ñ–≤, –∑–∞–º—ñ–Ω—é—é—á–∏ –ø—Ä–æ–±—ñ–ª–∏ –Ω–∞ \s+
        entry_range_match = re.search(r"–ù–∞—á–∏–Ω–∞—é\s+–æ—Ç–∫—Ä—ã–≤–∞—Ç—å\s+(–ª–æ–Ω–≥|—à–æ—Ä—Ç)\s+–≤\s+–¥–∏–∞–ø–∞–∑–æ–Ω–µ\s+—Ü–µ–Ω—ã\s+([\d.,]+)\s*-\s*([\d.,]+)", text, re.IGNORECASE)
        if entry_range_match:
            signal_data["direction"] = "LONG" if entry_range_match.group(1).lower() == "–ª–æ–Ω–≥" else "SHORT"
            # –í–∏—Ç—è–≥—É—î–º–æ –æ–±–∏–¥–≤—ñ –º–µ–∂—ñ, –∞–ª–µ –¥–ª—è –ª—ñ–º—ñ—Ç–∫–∏ –±–µ—Ä–µ–º–æ –¥—Ä—É–≥—É (min)
            price_high_str = entry_range_match.group(2)
            price_low_str = entry_range_match.group(3)
            signal_data["limit_order_price"] = safe_float(price_low_str)
            logger.debug(f"  [C3] –ó–Ω–∞–π–¥–µ–Ω–æ –Ω–∞–ø—Ä—è–º–æ–∫: {signal_data['direction']}, –¥—ñ–∞–ø–∞–∑–æ–Ω: {price_high_str}-{price_low_str}, —Ü—ñ–Ω–∞ –ª—ñ–º—ñ—Ç—É: {signal_data['limit_order_price']}")
            if signal_data["limit_order_price"] is None:
                 logger.warning("  [C3] –ù–µ –≤–¥–∞–ª–æ—Å—è –∫–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ –Ω–∏–∂–Ω—é –º–µ–∂—É –¥—ñ–∞–ø–∞–∑–æ–Ω—É –≤ —Ü—ñ–Ω—É –ª—ñ–º—ñ—Ç–Ω–æ–≥–æ –æ—Ä–¥–µ—Ä–∞, –∞–ª–µ –ø—Ä–æ–¥–æ–≤–∂—É—î–º–æ (–¥–ª—è –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ market + limit).")
        else:
            # –Ø–∫—â–æ –¥—ñ–∞–ø–∞–∑–æ–Ω—É –Ω–µ–º–∞—î, —Ü–µ –ø—Ä–æ—Å—Ç–æ MARKET —Å–∏–≥–Ω–∞–ª (–∞–ª–µ –¥–ª—è –î–∂–∏–º–º—ñ —Ü–µ –Ω–µ –æ—á—ñ–∫—É–≤–∞–Ω–æ)
            # –ê–±–æ –º–æ–∂–µ –±—É—Ç–∏ —ñ–Ω—à–∏–π —Ñ–æ—Ä–º–∞—Ç, —è–∫–∏–π –º–∏ —â–µ –Ω–µ –æ–±—Ä–æ–±–ª—è—î–º–æ
            logger.warning("  [C3] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ä—è–¥–æ–∫ '–ù–∞—á–∏–Ω–∞—é –æ—Ç–∫—Ä—ã–≤–∞—Ç—å...' –∑ –¥—ñ–∞–ø–∞–∑–æ–Ω–æ–º —Ü—ñ–Ω. –ú–æ–∂–ª–∏–≤–æ, —ñ–Ω—à–∏–π —Ñ–æ—Ä–º–∞—Ç —Å–∏–≥–Ω–∞–ª—É?")
            # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ None, —è–∫—â–æ –¥—ñ–∞–ø–∞–∑–æ–Ω –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–π –¥–ª—è —Ü—å–æ–≥–æ –∫–∞–Ω–∞–ª—É –∑–∞ –Ω–æ–≤–æ—é –ª–æ–≥—ñ–∫–æ—é
            return None # –ü–æ–∫–∏ —â–æ –≤–≤–∞–∂–∞—î–º–æ –¥—ñ–∞–ø–∞–∑–æ–Ω –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–º –¥–ª—è –ª–æ–≥—ñ–∫–∏ market+limit

        # 2. –ü–∞—Ä–∞ (–®—É–∫–∞—î–º–æ –¢–Ü–ö–ï–† –ø–µ—Ä–µ–¥ —Ä—è–¥–∫–æ–º "–ù–∞—á–∏–Ω–∞—é –æ—Ç–∫—Ä—ã–≤–∞—Ç—å")
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ entry_range_match —ñ—Å–Ω—É—î –ø–µ—Ä–µ–¥ –¥–æ—Å—Ç—É–ø–æ–º –¥–æ start()
        if not entry_range_match:
             logger.error("  [C3] –õ–æ–≥—ñ—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: entry_range_match –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, –∞–ª–µ –∫–æ–¥ –ø—Ä–æ–¥–æ–≤–∂–∏–≤ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è.")
             return None
             
        entry_range_start_index = entry_range_match.start()
        text_before_entry = text[:entry_range_start_index]
        pair_ticker_match = None
        for match in re.finditer(r"\b([A-Z]{3,})\b", text_before_entry):
            pair_ticker_match = match # –ó–∞–ø–∞–º'—è—Ç–æ–≤—É—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π
        
        if pair_ticker_match:
            signal_data["pair"] = normalize_pair(pair_ticker_match.group(1))
            logger.debug(f"  [C3] –ó–Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä—É (—Ç—ñ–∫–µ—Ä): {signal_data['pair']}")
        else:
            # –Ø–∫—â–æ —Ç—ñ–∫–µ—Ä –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, —Å–ø—Ä–æ–±—É—î–º–æ –∑–Ω–∞–π—Ç–∏ —â–æ—Å—å —Ç–∏–ø—É xxx/usdt
            pair_slash_match = re.search(r"\b(\w+/usdt)\b", text_before_entry, re.IGNORECASE)
            if pair_slash_match:
                signal_data["pair"] = normalize_pair(pair_slash_match.group(1))
                logger.debug(f"  [C3] –ó–Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä—É (xxx/usdt): {signal_data['pair']}")
            else:
                logger.warning("  [C3] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ç—ñ–∫–µ—Ä –ø–∞—Ä–∏ —É —Ç–µ–∫—Å—Ç—ñ –ø–µ—Ä–µ–¥ –æ–ø–∏—Å–æ–º –≤—Ö–æ–¥—É.")
                return None # –û–±–æ–≤'—è–∑–∫–æ–≤–µ –ø–æ–ª–µ

        # 3. –°—Ç–æ–ø-–ª–æ—Å—Å
        # –ó—Ä–æ–±–∏–º–æ regex –±—ñ–ª—å—à –≥–Ω—É—á–∫–∏–º –¥–æ –ø—Ä–æ–±—ñ–ª—ñ–≤
        sl_match = re.search(r"–°–ª\s+—Å—Ç–∞–≤–ª—é\s+–Ω–∞\s+([\d.,]+)", text, re.IGNORECASE)
        if sl_match:
            signal_data["stop_loss"] = safe_float(sl_match.group(1))
            logger.debug(f"  [C3] –ó–Ω–∞–π–¥–µ–Ω–æ —Å—Ç–æ–ø-–ª–æ—Å—Å: {signal_data['stop_loss']}")
        else:
            logger.warning("  [C3] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Å—Ç–æ–ø-–ª–æ—Å—Å ('–°–ª —Å—Ç–∞–≤–ª—é –Ω–∞...').")
            return None # –û–±–æ–≤'—è–∑–∫–æ–≤–µ

        # 4. –¢–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏ (–†–æ–∑–¥—ñ–ª—å–Ω–∏–∫ " –∏ ")
        tp_match = re.search(r"–ú–æ–∏ —Ü–µ–ª–∏ –Ω–∞ —Å–¥–µ–ª–∫—É\s+(.+)", text, re.IGNORECASE)
        if tp_match:
            tp_str = tp_match.group(1).strip()
            # –†–æ–∑–¥—ñ–ª—è—î–º–æ –ø–æ " –∏ ", –æ—á–∏—â—É—î–º–æ –ö–û–ñ–ù–£ —á–∞—Å—Ç–∏–Ω—É –≤—ñ–¥ –Ω–µ—á–∏—Å–ª–æ–≤–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤ (–∫—Ä—ñ–º . ,) —ñ –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ
            take_profits = []
            for part in tp_str.split(" –∏ "):
                # –í–∏–¥–∞–ª—è—î–º–æ –≤—Å–µ, —â–æ –Ω–µ —î —Ü–∏—Ñ—Ä–æ—é, –∫—Ä–∞–ø–∫–æ—é –∞–±–æ –∫–æ–º–æ—é
                cleaned_part = re.sub(r"[^\d.,]", "", part.strip())
                profit_value = safe_float(cleaned_part)
                if profit_value is not None:
                    take_profits.append(profit_value)

            signal_data["take_profits"] = take_profits
            logger.debug(f"  [C3] –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏: {signal_data['take_profits']}")

            if not signal_data["take_profits"]:
                logger.warning("  [C3] –ó–Ω–∞–π–¥–µ–Ω–æ —Ä—è–¥–æ–∫ '–ú–æ–∏ —Ü–µ–ª–∏...', –∞–ª–µ –Ω–µ –≤–¥–∞–ª–æ—Å—è –≤–∏—Ç—è–≥—Ç–∏ –∂–æ–¥–Ω–æ–≥–æ —á–∏—Å–ª–æ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–Ω—è —Ç–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç—É.")
        else:
            logger.warning("  [C3] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ä—è–¥–æ–∫ '–ú–æ–∏ —Ü–µ–ª–∏ –Ω–∞ —Å–¥–µ–ª–∫—É...'.")

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏—Ö –ø–æ–ª—ñ–≤ (–≤–∫–ª—é—á–∞—é—á–∏ –ø–µ—Ä–µ–≤—ñ—Ä–∫—É —Ç–∏–ø—É –æ—Ä–¥–µ—Ä–∞)
        required_fields_ok = all([
            signal_data["pair"],
            signal_data["direction"],
            signal_data["stop_loss"]
        ])
        # --- –í–∏–¥–∞–ª—è—î–º–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π –±–ª–æ–∫ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –¥–ª—è MARKET ---
        # # –î–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–ª—è –ª—ñ–º—ñ—Ç–Ω–æ–≥–æ –æ—Ä–¥–µ—Ä–∞
        # if signal_data["entry_price"] == "LIMIT" and signal_data["limit_order_price"] is None:
        #      logger.warning("  [C3] –¢–∏–ø –æ—Ä–¥–µ—Ä–∞ LIMIT, –∞–ª–µ —Ü—ñ–Ω–∞ –ª—ñ–º—ñ—Ç—É –≤—ñ–¥—Å—É—Ç–Ω—è –∞–±–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞.")
        #      return None
        # elif signal_data["entry_price"] == "MARKET":
        #     # –ü–æ–∫–∏ —â–æ –¥–ª—è –∫–∞–Ω–∞–ª—É 3 –Ω–µ–º–∞—î –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ MARKET –æ—Ä–¥–µ—Ä—ñ–≤, —Ç–æ–º—É —è–∫—â–æ —Å—é–¥–∏ –¥—ñ–π—à–ª–æ, —Ü–µ –ø–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É
        #     logger.warning("  [C3] –ü–∞—Ä—Å–µ—Ä –Ω–µ –∑–Ω–∞–π—à–æ–≤ –¥—ñ–∞–ø–∞–∑–æ–Ω —Ü—ñ–Ω, –∞–ª–µ –¥—ñ–π—à–æ–≤ –¥–æ –∫—ñ–Ω—Ü—è. –¶–µ –Ω–µ –æ—á—ñ–∫—É–≤–∞–Ω–æ –¥–ª—è –∫–∞–Ω–∞–ª—É 3.")
        #     return None

        if not required_fields_ok:
            logger.warning("  [C3] –ù–µ –≤—Å—ñ –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ –ø–æ–ª—è (pair, direction, stop_loss) –±—É–ª–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ.")
            return None

        # --- –î–æ–¥–∞—Ç–∫–æ–≤–µ –ª–æ–≥—É–≤–∞–Ω–Ω—è –ø–µ—Ä–µ–¥ —É—Å–ø—ñ—à–Ω–∏–º –ø–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è–º ---
        logger.debug("  [C3] –£—Å—ñ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ñ. –ü–æ–≤–µ—Ä—Ç–∞—é —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω—ñ –¥–∞–Ω—ñ.")
        # 6. Log success and return data
        logger.info(f"  [C3] –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ —Å–∏–≥–Ω–∞–ª: { {k: v for k, v in signal_data.items() if k != 'raw_text'} }")
        return signal_data

    except Exception as e:
        logger.error(f"  [C3] –ù–µ–æ—á—ñ–∫—É–≤–∞–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–∞—Ä—Å–∏–Ω–≥—É –∫–∞–Ω–∞–ª—É 3: {e}", exc_info=True)
        return None

# --- Parser for Channel 4 (KostyaKogan - –æ–¥–Ω–æ–µ—Ç–∞–ø–Ω–∏–π) ---
def parse_channel_4(text: str, config: dict):
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∫–∞–Ω–∞–ª—É 4 (KostyaKogan), —è–∫–∏–π –Ω–∞–¥—Å–∏–ª–∞—î –≤—Å–µ –≤ –æ–¥–Ω–æ–º—É –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—ñ."""
    logger.debug("  [C4] –°–ø—Ä–æ–±–∞ –ø–∞—Ä—Å–∏–Ω–≥—É —è–∫ –æ–¥–Ω–æ–µ—Ç–∞–ø–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª—É")
    signal_data = {
        "type": "full", # –ü–æ–∑–Ω–∞—á–∞—î–º–æ —è–∫ –ø–æ–≤–Ω–∏–π —Å–∏–≥–Ω–∞–ª
        "source": "channel_4",
        "source_name": config.get('channels', {}).get('channel_4', {}).get('name', 'KostyaKogan'),
        "pair": None,
        "direction": None,
        "entry_price": "MARKET", # –í—Ö—ñ–¥ –ø–æ —Ä–∏–Ω–∫—É
        "take_profits": [],
        "stop_loss": None,
        "leverage": None, # –î–æ–¥–∞—î–º–æ –ø–æ–ª–µ –¥–ª—è –ø–ª–µ—á–∞
        "raw_text": text,
    }

    try:
        # 1. –ü–∞—Ä–∞ —Ç–∞ –ù–∞–ø—Ä—è–º–æ–∫ (–®—É–∫–∞—î–º–æ –≤ –ø–µ—Ä—à–æ–º—É —Ä—è–¥–∫—É —Ç–∏–ø—É "–û—Ç–∫—Ä—ã–ª UXLINK long")
        first_line = text.splitlines()[0] if text.splitlines() else ""
        pair_match = re.search(r"–û—Ç–∫—Ä—ã–ª\s+([A-Z0-9/]+)\s+(long|short)", first_line, re.IGNORECASE)
        if pair_match:
            signal_data["pair"] = normalize_pair(pair_match.group(1))
            signal_data["direction"] = pair_match.group(2).upper()
            logger.debug(f"  [C4] –ó–Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä—É: {signal_data['pair']}, –Ω–∞–ø—Ä—è–º–æ–∫: {signal_data['direction']}")
        else:
            logger.warning("  [C4] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –ø–∞—Ä—É —Ç–∞ –Ω–∞–ø—Ä—è–º–æ–∫ —É –ø–µ—Ä—à–æ–º—É —Ä—è–¥–∫—É ('–û—Ç–∫—Ä—ã–ª...').")
            return None # –û–±–æ–≤'—è–∑–∫–æ–≤—ñ

        # 2. –ü–ª–µ—á–µ (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
        leverage_match = re.search(r"–ø–ª–µ—á–æ:\s*(\d+)x?", text, re.IGNORECASE)
        if leverage_match:
            try:
                signal_data["leverage"] = int(leverage_match.group(1))
                logger.debug(f"  [C4] –ó–Ω–∞–π–¥–µ–Ω–æ –ø–ª–µ—á–µ: {signal_data['leverage']}")
            except ValueError:
                 logger.warning("  [C4] –ù–µ –≤–¥–∞–ª–æ—Å—è –∫–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ –ø–ª–µ—á–µ –≤ —á–∏—Å–ª–æ.")
        else:
             logger.debug("  [C4] –ü–ª–µ—á–µ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")

        # 3. –°—Ç–æ–ø-–ª–æ—Å—Å
        sl_match = re.search(r"—Å—Ç–æ–ø:\s*([\d.,]+)", text, re.IGNORECASE)
        if sl_match:
            signal_data["stop_loss"] = safe_float(sl_match.group(1))
            logger.debug(f"  [C4] –ó–Ω–∞–π–¥–µ–Ω–æ —Å—Ç–æ–ø-–ª–æ—Å—Å: {signal_data['stop_loss']}")
        else:
            logger.warning("  [C4] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Å—Ç–æ–ø-–ª–æ—Å—Å ('—Å—Ç–æ–ø:...').")
            return None # –û–±–æ–≤'—è–∑–∫–æ–≤–µ

        # 4. –¢–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏ (–†–æ–∑–¥—ñ–ª—å–Ω–∏–∫ ", ")
        tp_match = re.search(r"—Ç–µ–π–∫:\s*(.+)", text, re.IGNORECASE)
        if tp_match:
            tp_str = tp_match.group(1).strip()
            signal_data["take_profits"] = [p for p in (safe_float(val.strip()) for val in tp_str.split(',')) if p is not None]
            logger.debug(f"  [C4] –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏: {signal_data['take_profits']}")
        else:
            logger.warning("  [C4] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ç–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏ ('—Ç–µ–π–∫:...').")
            # –¢–µ–π–∫–∏ —Ç—É—Ç, —Å—Ö–æ–∂–µ, –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ?

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏—Ö –ø–æ–ª—ñ–≤
        if not all([signal_data["pair"], signal_data["direction"], signal_data["stop_loss"]]):
             logger.warning("  [C4] –ù–µ –≤—Å—ñ –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ –ø–æ–ª—è (pair, direction, stop_loss) –±—É–ª–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ.")
             return None

        logger.info(f"  [C4] –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ —Å–∏–≥–Ω–∞–ª: { {k: v for k, v in signal_data.items() if k != 'raw_text'} }")
        return signal_data

    except Exception as e:
        logger.error(f"  [C4] –ù–µ–æ—á—ñ–∫—É–≤–∞–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–∞—Ä—Å–∏–Ω–≥—É –∫–∞–Ω–∞–ª—É 4: {e}", exc_info=True)
        return None

# --- Parser for Channel 5 (VALERIY LONG/SHORT) --- 

def parse_channel_5_entry(text: str):
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –ü–ï–†–®–û–ì–û –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–∞–Ω–∞–ª—É 5 ('–ó–∞—Ö–æ–∂—É...')."""
    logger.debug("  [C5 Entry] –°–ø—Ä–æ–±–∞ –ø–∞—Ä—Å–∏–Ω–≥—É —è–∫ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è '–ó–∞—Ö–æ–∂—É...'")
    # –ü–∞—Ç–µ—Ä–Ω: "–ó–∞—Ö–æ–∂—É" + –ø—Ä–æ–±—ñ–ª + (–≤ LONG / –≤ SHORT) + "–ø–æ –º–æ–Ω–µ—Ç–µ" + –ø—Ä–æ–±—ñ–ª + (#–°–∏–º–≤–æ–ª) + ...
    # –î–æ–¥–∞—î–º–æ # –¥–æ —Å–∏–º–≤–æ–ª—É —ñ —Ä–æ–±–∏–º–æ –π–æ–≥–æ –Ω–µ–æ–±–æ–≤'—è–∑–∫–æ–≤–∏–º, —à—É–∫–∞—î–º–æ –≤–µ–ª–∏–∫—ñ –ª—ñ—Ç–µ—Ä–∏ + USDT
    match = re.search(r"–ó–∞—Ö–æ–∂—É\s+(?:–≤\s+)?(LONG|SHORT)\s+–ø–æ\s+–º–æ–Ω–µ—Ç–µ\s+#?([A-Z0-9/]+USDT)", text, re.IGNORECASE)
    if match:
        direction = match.group(1).upper()
        pair_raw = match.group(2) # –í–∂–µ –º–∞—î –º—ñ—Å—Ç–∏—Ç–∏ USDT
        pair = normalize_pair(pair_raw)
        logger.info(f"  [C5 Entry] –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ –≤—Ö—ñ–¥–Ω–∏–π —Å–∏–≥–Ω–∞–ª: Pair={pair}, Direction={direction}")
        return {"type": "entry", "pair": pair, "direction": direction}
    logger.debug("  [C5 Entry] –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ç–µ—Ä–Ω '–ó–∞—Ö–æ–∂—É...'")
    return None

def parse_channel_5_details(text: str, config: dict):
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –î–†–£–ì–û–ì–û –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–∞–Ω–∞–ª—É 5 (–∑ –¥–µ—Ç–∞–ª—è–º–∏ TP/SL)."""
    logger.debug("  [C5 Details] –°–ø—Ä–æ–±–∞ –ø–∞—Ä—Å–∏–Ω–≥—É —è–∫ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑ –¥–µ—Ç–∞–ª—è–º–∏ (COIN...) ")
    logger.debug(f"  [C5 Details] –í—Ö—ñ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É –ø–∞—Ä–∏: {repr(text[:100])}...") # –õ–æ–≥—É—î–º–æ –ø–µ—Ä—à—ñ 100 —Å–∏–º–≤–æ–ª—ñ–≤
    signal_data = {
        "type": "details",
        "source": "channel_5",
        "source_name": config.get('channels', {}).get('channel_5', {}).get('name', 'VALERIY LONG/SHORT'),
        "pair": None,
        "direction": None, # –ó–∞–ª–∏—à–∞—î–º–æ None, –±—É–¥–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –≤ main.py
        "entry_price": "MARKET", # –í—Ö—ñ–¥ –ø–æ —Ä–∏–Ω–∫—É
        "take_profits": [],
        "stop_loss": None,
        "raw_text": text,
    }

    try:
        # 1. –ü–∞—Ä–∞ (–∑ —Ä—è–¥–∫–∞ \"COIN...\") - –û–¥–∏–Ω–∞—Ä–Ω–∏–π —Å–ª–µ—à –¥–ª—è –ø—Ä–æ–±—ñ–ª—É!
        pair_match = re.search(r"COIN\s*ü™ô?\s*([A-Z0-9/]+USDT)", text, re.IGNORECASE) # <-- –û–¥–∏–Ω–∞—Ä–Ω–∏–π \s
        if pair_match:
            signal_data["pair"] = normalize_pair(pair_match.group(1))
            logger.debug(f"  [C5 Details] –ó–Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä—É: {signal_data['pair']} (–∑ {pair_match.group(1)})")
        else:
            logger.warning("  [C5 Details] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –ø–∞—Ä—É ('COIN...XXXUSDT').")
            return None # –û–±–æ–≤'—è–∑–∫–æ–≤–µ –ø–æ–ª–µ

        # 2. –¢–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏ (–®—É–∫–∞—î–º–æ —Ä—è–¥–∫–∏, —â–æ –ø–æ—á–∏–Ω–∞—é—Ç—å—Å—è –∑ ‚úÖTP:) - –û–¥–∏–Ω–∞—Ä–Ω–∏–π —Å–ª–µ—à!
        tp_lines = re.findall(r"‚úÖ\s*TP:\s*([\d.,]+)", text) # <-- –û–¥–∏–Ω–∞—Ä–Ω–∏–π \s
        if tp_lines:
            signal_data["take_profits"] = [p for p in (safe_float(val) for val in tp_lines) if p is not None]
            logger.debug(f"  [C5 Details] –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏: {signal_data['take_profits']}")
        else:
            logger.warning("  [C5 Details] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ç–µ–π–∫-–ø—Ä–æ—Ñ—ñ—Ç–∏ (—Ä—è–¥–∫–∏ ‚úÖTP:).")
            # TP –º–æ–∂—É—Ç—å –±—É—Ç–∏ –Ω–µ–æ–±–æ–≤'—è–∑–∫–æ–≤–∏–º–∏?

        # 3. –°—Ç–æ–ø-–ª–æ—Å—Å (–®—É–∫–∞—î–º–æ —Ä—è–¥–æ–∫ "üö´Stop ...") - –û–¥–∏–Ω–∞—Ä–Ω–∏–π —Å–ª–µ—à!
        sl_match = re.search(r"üö´\s*Stop\s+([\d.,]+)", text, re.IGNORECASE) # <-- –û–¥–∏–Ω–∞—Ä–Ω–∏–π \s
        if sl_match:
            signal_data["stop_loss"] = safe_float(sl_match.group(1))
            logger.debug(f"  [C5 Details] –ó–Ω–∞–π–¥–µ–Ω–æ —Å—Ç–æ–ø-–ª–æ—Å—Å: {signal_data['stop_loss']}")
        else:
            logger.warning("  [C5 Details] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Å—Ç–æ–ø-–ª–æ—Å—Å ('üö´Stop...').")
            return None # –û–±–æ–≤'—è–∑–∫–æ–≤–µ –ø–æ–ª–µ

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏—Ö –ø–æ–ª—ñ–≤ (–±–µ–∑ –Ω–∞–ø—Ä—è–º–∫—É)
        if not all([signal_data["pair"], signal_data["stop_loss"]]):
             logger.warning("  [C5 Details] –ù–µ –≤—Å—ñ –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ –ø–æ–ª—è (pair, stop_loss) –±—É–ª–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ.")
             return None

        logger.info(f"  [C5 Details] –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ –¥–µ—Ç–∞–ª—ñ —Å–∏–≥–Ω–∞–ª—É (–±–µ–∑ –Ω–∞–ø—Ä—è–º–∫—É): { {k: v for k, v in signal_data.items() if k != 'raw_text'} }")
        return signal_data # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –¥–∞–Ω—ñ –±–µ–∑ –Ω–∞–ø—Ä—è–º–∫—É

    except Exception as e:
        logger.error(f"  [C5 Details] –ù–µ–æ—á—ñ–∫—É–≤–∞–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–∞—Ä—Å–∏–Ω–≥—É –¥–µ—Ç–∞–ª–µ–π –∫–∞–Ω–∞–ª—É 5: {e}", exc_info=True)
        return None 